# Hyperparameter Tuning & Feature Selection

## ğŸ¯ YapÄ±lan Ä°yileÅŸtirmeler

### 1. **GeliÅŸmiÅŸ Hyperparameter Tuning**
- **RandomizedSearchCV** ile 30 iterasyon (Ã¶nceden 20)
- Daha geniÅŸ parametre aralÄ±ÄŸÄ±:
  - `n_estimators`: [200, 300, 400, 500, 700, 1000]
  - `max_depth`: [8, 10, 12, 15, 20, 25, None]
  - `min_samples_leaf`: [1, 2, 4, 6, 8]
  - `min_samples_split`: [2, 5, 10, 15, 20]
  - `max_features`: ["sqrt", "log2", 0.5, 0.7, None]
  - `class_weight`: ["balanced", "balanced_subsample", None]

### 2. **Feature Importance-Based Selection**
- **Tuned model** ile feature importance hesaplanÄ±r
- **Importance >= 0.05** olan feature'lar tutulur
- EÄŸer Ã§ok az feature kalÄ±rsa (<10), en iyi 10 feature tutulur
- KaldÄ±rÄ±lan feature'lar loglanÄ±r

### 3. **Yeni EÄŸitim AkÄ±ÅŸÄ±**

#### Dip Model:
1. TÃ¼m feature'larla hyperparameter tuning yapÄ±lÄ±r
2. Tuned model'in feature importance'larÄ± hesaplanÄ±r
3. Importance >= 0.05 olan feature'lar seÃ§ilir
4. SeÃ§ilen feature'larla model yeniden fit edilir

#### Peak Model:
1. Oversampling yapÄ±lÄ±r (minority class 10x artÄ±rÄ±lÄ±r)
2. TÃ¼m feature'larla hyperparameter tuning yapÄ±lÄ±r
3. Tuned model'in feature importance'larÄ± hesaplanÄ±r
4. Importance >= 0.05 olan feature'lar seÃ§ilir
5. SeÃ§ilen feature'larla model yeniden fit edilir

---

## ğŸ“Š Test SonuÃ§larÄ±

### Feature Reduction:
- **Dip Model**: 44 â†’ 10 feature (77% azalma)
- **Peak Model**: 27 â†’ 10 feature (63% azalma)

### Top Features (Importance > 0.05):

#### Dip Model:
1. **Leg_Return** (0.2373) - Son pivot'tan bu yana fiyat deÄŸiÅŸimi
2. **Drawdown_Pct** (0.1436) - Son yÃ¼ksekten dÃ¼ÅŸÃ¼ÅŸ yÃ¼zdesi
3. **Price_Exhaustion_5D** (0.1246) - Son 5 gÃ¼nde fiyat tÃ¼kenmesi
4. **Price_Exhaustion_10D** (0.0963) - Son 10 gÃ¼nde fiyat tÃ¼kenmesi
5. **Cycle_Length** (0.0828) - Mevcut dÃ¶ngÃ¼ uzunluÄŸu

#### Peak Model:
1. **ATR** (0.1757) - Average True Range
2. **ATR_Expansion_5D** (0.1462) - Volatilite geniÅŸlemesi
3. **RSI_Overbought_Days** (0.1428) - AÅŸÄ±rÄ± alÄ±m sÃ¼resi
4. **Kurtosis_20** (0.1125) - Fiyat daÄŸÄ±lÄ±mÄ± kurtosis
5. **MFI_14** (0.0968) - Money Flow Index

### Model Performance:
- **Dip Model**: Precision: 0.388, Recall: 0.904, Accuracy: 0.582
- **Peak Model**: Precision: 0.539, Recall: 0.760, Accuracy: 0.534

---

## ğŸ” Ã–nemli GÃ¶zlemler

### Yeni Feature'larÄ±n Etkisi:
- **Cycle_Length_Ratio**: Hem Dip hem Peak model'de seÃ§ildi
- **Price_Exhaustion_***: Dip model'de gÃ¼Ã§lÃ¼ feature'lar
- **ATR_Expansion_5D**: Peak model'de 2. en Ã¶nemli feature
- **Trend_Exhaustion_Score**: SeÃ§ilmedi (muhtemelen diÄŸer feature'larla korelasyonlu)

### KaldÄ±rÄ±lan Feature'lar:
- DÃ¼ÅŸÃ¼k importance (< 0.05) olan feature'lar otomatik kaldÄ±rÄ±ldÄ±
- Model daha hÄ±zlÄ± ve daha az overfitting riski

---

## ğŸš€ KullanÄ±m

### Optimize=True (Ã–nerilen):
```python
engine = MLEngine(df)
metrics, backtest_df = engine.train(optimize=True)
# Hyperparameter tuning + Feature selection yapÄ±lÄ±r
```

### Optimize=False (HÄ±zlÄ±):
```python
engine = MLEngine(df)
metrics, backtest_df = engine.train(optimize=False)
# Sadece base model ile feature selection yapÄ±lÄ±r
```

---

## ğŸ“ Notlar

1. **Feature Selection**: Tuned model'in importance'larÄ±na gÃ¶re yapÄ±lÄ±r, bu daha doÄŸru sonuÃ§ verir
2. **Minimum Features**: En az 10 feature tutulur (Ã§ok az feature kalÄ±rsa)
3. **Logging**: Streamlit'te feature selection sÃ¼reci loglanÄ±r
4. **Performance**: Daha az feature = daha hÄ±zlÄ± inference, daha az overfitting

---

## ğŸ”„ Sonraki AdÄ±mlar

1. **Feature Importance Analizi**: Hangi feature'larÄ±n neden seÃ§ildiÄŸini analiz et
2. **Threshold Tuning**: 0.05 threshold'unu optimize et (0.03, 0.07, 0.10)
3. **Cross-Validation**: Feature selection'Ä±n stability'sini test et
4. **Ablation Study**: Her feature'Ä±n katkÄ±sÄ±nÄ± Ã¶lÃ§

