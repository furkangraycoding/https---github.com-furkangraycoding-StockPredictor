"""
Forward Testing: GerÃ§ek Dip/Zirve NoktalarÄ± iÃ§in Saf Sinyal BaÅŸarÄ±sÄ±
Her gerÃ§ek nokta iÃ§in, N gÃ¼n Ã¶ncesinden model eÄŸitip saf sinyal Ã¼retip Ã¼retmediÄŸini test eder.
"""
import pandas as pd
import numpy as np
from data_loader import load_data
from indicators import TechnicalAnalyzer
from ml_engine import MLEngine
import warnings
warnings.filterwarnings('ignore')

def find_real_pivots(df, date_col):
    """GerÃ§ek dip ve zirve noktalarÄ±nÄ± bulur (ZigZag ile belirlenmiÅŸ)"""
    # ZigZag ile pivot noktalarÄ±nÄ± bul
    analyzer = TechnicalAnalyzer(df)
    analyzer.add_atr(14)
    analyzer.add_zigzag_labels(threshold_pct=0.05)
    df_with_pivots = analyzer.get_df()
    
    # Dip noktalarÄ±
    dip_points = df_with_pivots[df_with_pivots["Dip"].notna()].copy()
    dip_points["type"] = "Dip"
    dip_points["pivot_price"] = dip_points["Dip"]
    
    # Zirve noktalarÄ±
    peak_points = df_with_pivots[df_with_pivots["Tepe"].notna()].copy()
    peak_points["type"] = "Peak"
    peak_points["pivot_price"] = peak_points["Tepe"]
    
    # BirleÅŸtir ve sÄ±rala
    all_pivots = pd.concat([dip_points, peak_points]).sort_values(date_col)
    
    return all_pivots, df_with_pivots

def train_and_check_pure_signal(df, df_analyzed, date_col, target_date, lookback_days, pivot_type):
    """
    Belirli bir tarihten N gÃ¼n Ã¶ncesine kadar veriyle model eÄŸitir
    ve o tarihte saf sinyal Ã¼retip Ã¼retmediÄŸini kontrol eder.
    
    Args:
        df: TÃ¼m veri
        date_col: Tarih kolonu
        target_date: Test edilecek tarih (gerÃ§ek pivot noktasÄ±)
        lookback_days: KaÃ§ gÃ¼n geriye gidilecek
        pivot_type: "Dip" veya "Peak"
    
    Returns:
        dict: SonuÃ§lar (pure_signal, dip_prob, peak_prob, etc.)
    """
    try:
        # Target date'i pandas Timestamp'e Ã§evir
        if isinstance(target_date, str):
            target_date = pd.to_datetime(target_date)
        
        # df_analyzed'de target date'in pozisyonunu bul
        target_mask = df_analyzed[date_col].dt.date == target_date.date()
        target_indices = df_analyzed[target_mask].index
        
        if len(target_indices) == 0:
            # Alternatif: en yakÄ±n tarihi bul
            date_diff = (df_analyzed[date_col].dt.date - target_date.date()).abs()
            closest_idx = date_diff.idxmin()
            target_pos = df_analyzed.index.get_loc(closest_idx)
        else:
            target_idx = target_indices[0]
            target_pos = df_analyzed.index.get_loc(target_idx)
        
        # Lookback: target_date'ten N gÃ¼n Ã¶ncesine kadar olan TÃœM veriyi kullan
        # lookback_days=0 ise, maksimum veri kullan (target_date'e kadar, target hariÃ§)
        if lookback_days == 0:
            # Maksimum veri kullan (target_date'e kadar, target hariÃ§)
            start_pos = 0  # En baÅŸtan baÅŸla
            end_pos = target_pos  # Target'a kadar (target hariÃ§)
        else:
            # N gÃ¼n Ã¶ncesine kadar: target_date'ten N gÃ¼n Ã¶ncesine kadar olan tÃ¼m veri
            # Ã–nce N gÃ¼n Ã¶ncesini bul
            target_date_obj = df_analyzed.iloc[target_pos][date_col]
            lookback_date = target_date_obj - pd.Timedelta(days=lookback_days)
            
            # Lookback date'ten Ã¶nceki tÃ¼m veriyi kullan
            lookback_mask = df_analyzed[date_col] <= lookback_date
            if lookback_mask.sum() > 0:
                start_pos = 0  # En baÅŸtan baÅŸla
                # Lookback date'e kadar olan son satÄ±r
                lookback_indices = df_analyzed[lookback_mask].index
                end_pos = df_analyzed.index.get_loc(lookback_indices[-1]) + 1
            else:
                # EÄŸer lookback date Ã§ok erken ise, sadece target'tan N gÃ¼n Ã¶ncesi
                start_pos = max(0, target_pos - lookback_days)
                end_pos = target_pos
        
        train_data = df_analyzed.iloc[start_pos:end_pos].copy()
        
        # Minimum veri kontrolÃ¼ (lookback'e gÃ¶re esnek)
        # KÃ¼Ã§Ã¼k lookback'ler iÃ§in daha az veri yeterli
        if lookback_days == 0:
            min_required = 100
        elif lookback_days <= 2:
            min_required = 20  # 1-2 gÃ¼n iÃ§in minimum
        else:
            min_required = 30  # 3-5 gÃ¼n iÃ§in minimum
        
        if len(train_data) < min_required:
            if lookback_days == 5:  # Sadece ilk lookback'te log
                print(f"     â†’ Yetersiz veri: {len(train_data)} satÄ±r (min {min_required} gerekli)")
            return None
        
        # train_data zaten df_analyzed'den geldi, tÃ¼m feature'lar var
        # Sadece ZigZag label'larÄ±nÄ± yeniden hesapla (lookback window iÃ§in)
        # Ã‡Ã¼nkÃ¼ ZigZag label'larÄ± tÃ¼m veri Ã¼zerinde hesaplanmÄ±ÅŸ olabilir
        train_analyzer = TechnicalAnalyzer(train_data)
        if "ATR" not in train_data.columns:
            train_analyzer.add_atr(14)
        train_analyzer.add_zigzag_labels(threshold_pct=0.05)
        train_data = train_analyzer.get_df()
        
        # Eksik feature'larÄ± ekle
        if "Volatility_20" not in train_data.columns:
            train_analyzer.add_rolling_volatility()
        if "Drawdown_Pct" not in train_data.columns:
            train_analyzer.add_drawdown_features()
        train_data = train_analyzer.add_derived_features()
        
        engine = MLEngine(train_data)
        metrics, _ = engine.train(optimize=False)  # HÄ±zlÄ± eÄŸitim
        
        # Target date ve sonraki 3 gÃ¼nÃ¼ iÃ§eren window oluÅŸtur
        # Forward confirmation iÃ§in sonraki gÃ¼nler gerekli
        target_date_analyzed = df_analyzed[df_analyzed[date_col].dt.date == target_date.date()]
        if len(target_date_analyzed) == 0:
            # En yakÄ±n tarihi bul
            date_diff = (df_analyzed[date_col].dt.date - target_date.date()).abs()
            closest_idx = date_diff.idxmin()
            target_pos_in_analyzed = df_analyzed.index.get_loc(closest_idx)
        else:
            target_pos_in_analyzed = df_analyzed.index.get_loc(target_date_analyzed.index[0])
        
        # Target date'ten sonraki 3 gÃ¼nÃ¼ de al (forward confirmation iÃ§in)
        end_pos = min(len(df_analyzed), target_pos_in_analyzed + 4)  # Target + 3 gÃ¼n sonrasÄ±
        prediction_window = df_analyzed.iloc[max(0, target_pos_in_analyzed - 4):end_pos].copy()
        
        if len(prediction_window) < 5:  # En az target + 1 gÃ¼n sonrasÄ± gerekli
            if lookback_days == 5:
                print(f"     â†’ Forward confirmation iÃ§in yetersiz veri")
            return None
        
        # Forward confirmation ile saf sinyal kontrolÃ¼
        # MLEngine'in add_predictions_to_df metodunu kullan (forward confirmation dahil)
        df_with_predictions = engine.add_predictions_to_df(
            prediction_window.copy(), 
            use_forward_confirmation=True
        )
        
        # Target gÃ¼nÃ¼n sinyalini kontrol et
        target_mask = df_with_predictions[date_col].dt.date == target_date.date()
        if target_mask.sum() == 0:
            # En yakÄ±n tarihi bul
            date_diff = (df_with_predictions[date_col].dt.date - target_date.date()).abs()
            closest_idx = date_diff.idxmin()
            target_row_pred = df_with_predictions.loc[closest_idx]
        else:
            target_row_pred = df_with_predictions[target_mask].iloc[0]
        
        # SonuÃ§
        if pivot_type == "Dip":
            pure_signal = target_row_pred["AI_Dip"] == 1
            signal_prob = target_row_pred["AI_Dip_Prob"]
            dip_prob = target_row_pred["AI_Dip_Prob"]
            peak_prob = target_row_pred["AI_Peak_Prob"]
        else:  # Peak
            pure_signal = target_row_pred["AI_Peak"] == 1
            signal_prob = target_row_pred["AI_Peak_Prob"]
            dip_prob = target_row_pred["AI_Dip_Prob"]
            peak_prob = target_row_pred["AI_Peak_Prob"]
        
        # Gap deÄŸerleri (raporlama iÃ§in)
        peak_gap = (target_row_pred["AI_Peak_Prob"] - target_row_pred["AI_Dip_Prob"]) * 100
        dip_gap = (target_row_pred["AI_Dip_Prob"] - target_row_pred["AI_Peak_Prob"]) * 100
        
        # RSI deÄŸeri
        rsi = target_row_pred.get("RSI", target_row_pred.get("rsi_14", 50))
        if pd.isna(rsi):
            rsi = 50  # Default
        peak_threshold = rsi * 0.48
        
        return {
            "lookback_days": lookback_days,
            "pure_signal": pure_signal,
            "dip_prob": dip_prob,
            "peak_prob": peak_prob,
            "signal_prob": signal_prob,
            "rsi": rsi,
            "train_size": len(train_data),
            "peak_gap": peak_gap,
            "dip_gap": dip_gap,
            "peak_threshold": peak_threshold
        }
    except Exception as e:
        import traceback
        # Ä°lk pivot'ta detaylÄ± hata gÃ¶ster
        if lookback_days == 5:
            error_msg = str(e)[:100]  # Ä°lk 100 karakter
            print(f"  âš ï¸ Hata (lookback={lookback_days}): {type(e).__name__}: {error_msg}")
            if "Last_Signal" in str(e) or "Label" in str(e):
                print(f"     â†’ Muhtemelen ZigZag label'larÄ± eksik")
            elif "KeyError" in str(e):
                print(f"     â†’ Eksik kolon hatasÄ±")
        return None

def forward_test_pure_signals():
    """Ana test fonksiyonu"""
    print("=" * 80)
    print("FORWARD TEST: GerÃ§ek Pivot NoktalarÄ± iÃ§in Saf Sinyal BaÅŸarÄ±sÄ±")
    print("=" * 80)
    
    # Veri yÃ¼kle
    df, date_col = load_data('BIST100_PREDICTION_READY.csv')
    print(f"\nâœ“ Veri yÃ¼klendi: {len(df)} satÄ±r")
    
    # Tarih kolonunu kontrol et
    if date_col not in df.columns:
        print(f"âŒ Tarih kolonu bulunamadÄ±: {date_col}")
        return
    
    df[date_col] = pd.to_datetime(df[date_col])
    
    # 2025 yÄ±lÄ± pivot noktalarÄ±nÄ± bulmak iÃ§in tÃ¼m veriyi kullan
    # Ama sadece 2025 yÄ±lÄ±ndaki pivot'larÄ± test edeceÄŸiz
    print(f"âœ“ TÃ¼m veri kullanÄ±lacak (2025 pivot'larÄ± iÃ§in): {len(df)} satÄ±r")
    
    # Feature'larÄ± hazÄ±rla (tÃ¼m veri Ã¼zerinde)
    print("\nğŸ“Š Feature'lar hazÄ±rlanÄ±yor...")
    analyzer = TechnicalAnalyzer(df)
    analyzer.add_moving_averages()
    analyzer.add_rsi()
    analyzer.add_atr()
    analyzer.determine_regime()
    analyzer.add_zigzag_labels(threshold_pct=0.05)
    analyzer.add_rolling_volatility()
    analyzer.add_drawdown_features()
    df_analyzed = analyzer.add_derived_features()
    
    # 2025 yÄ±lÄ± pivot noktalarÄ±nÄ± bul
    print("\nğŸ” GerÃ§ek pivot noktalarÄ± bulunuyor...")
    all_pivots, df_with_pivots = find_real_pivots(df_analyzed, date_col)
    
    # 2025 yÄ±lÄ± pivot'larÄ±
    pivots_2025 = all_pivots[all_pivots[date_col].dt.year == 2025].copy()
    
    if len(pivots_2025) == 0:
        print("âŒ 2025 yÄ±lÄ±nda pivot noktasÄ± bulunamadÄ±")
        return
    
    print(f"âœ“ 2025 yÄ±lÄ±nda {len(pivots_2025)} pivot noktasÄ± bulundu")
    print(f"  - Dip: {len(pivots_2025[pivots_2025['type'] == 'Dip'])}")
    print(f"  - Peak: {len(pivots_2025[pivots_2025['type'] == 'Peak'])}")
    
    # Her pivot iÃ§in test
    results = []
    lookback_periods = [5, 4, 3, 2, 1, 0]  # 0 = tam gÃ¼n
    
    print("\n" + "=" * 80)
    print("TEST BAÅLIYOR...")
    print("=" * 80)
    
    for idx, pivot_row in pivots_2025.iterrows():
        pivot_date = pivot_row[date_col]
        pivot_type = pivot_row["type"]
        pivot_price = pivot_row["pivot_price"]
        
        print(f"\nğŸ“ {pivot_type} - {pivot_date.strftime('%Y-%m-%d')} @ {pivot_price:.2f}")
        
        # Her lookback period iÃ§in test
        for lookback in lookback_periods:
            result = train_and_check_pure_signal(
                df_analyzed, df_analyzed, date_col, pivot_date, lookback, pivot_type
            )
            
            if result:
                result["pivot_date"] = pivot_date
                result["pivot_type"] = pivot_type
                result["pivot_price"] = pivot_price
                results.append(result)
                
                status = "âœ…" if result["pure_signal"] else "âŒ"
                print(f"  {status} Lookback {lookback:2d}g: Pure={result['pure_signal']}, "
                      f"Prob={result['signal_prob']:.2f}, RSI={result['rsi']:.1f}")
            else:
                print(f"  âš ï¸  Lookback {lookback:2d}g: Yetersiz veri veya hata")
    
    # SonuÃ§larÄ± analiz et
    print("\n" + "=" * 80)
    print("SONUÃ‡LAR")
    print("=" * 80)
    
    results_df = pd.DataFrame(results)
    
    if len(results_df) == 0:
        print("âŒ SonuÃ§ bulunamadÄ±")
        return
    
    # Pivot tipine gÃ¶re grupla
    for pivot_type in ["Dip", "Peak"]:
        type_results = results_df[results_df["pivot_type"] == pivot_type]
        if len(type_results) == 0:
            continue
        
        print(f"\nğŸ“Š {pivot_type} NoktalarÄ±:")
        print("-" * 80)
        
        # Lookback period'a gÃ¶re baÅŸarÄ± oranÄ±
        for lookback in lookback_periods:
            lookback_results = type_results[type_results["lookback_days"] == lookback]
            if len(lookback_results) == 0:
                continue
            
            total = len(lookback_results)
            success = lookback_results["pure_signal"].sum()
            success_rate = (success / total * 100) if total > 0 else 0
            
            avg_prob = lookback_results["signal_prob"].mean()
            avg_rsi = lookback_results["rsi"].mean()
            
            print(f"  Lookback {lookback:2d}g: {success:2d}/{total:2d} baÅŸarÄ±lÄ± "
                  f"(%{success_rate:5.1f}) | Avg Prob: {avg_prob:.3f} | Avg RSI: {avg_rsi:.1f}")
        
        # Genel istatistikler
        total_pivots = type_results["pivot_date"].nunique()
        overall_success = type_results.groupby("pivot_date")["pure_signal"].any().sum()
        overall_rate = (overall_success / total_pivots * 100) if total_pivots > 0 else 0
        
        print(f"\n  ğŸ“ˆ Genel: {overall_success}/{total_pivots} pivot'ta en az 1 lookback'te saf sinyal "
              f"(%{overall_rate:.1f})")
    
    # En iyi lookback period
    print("\n" + "=" * 80)
    print("EN Ä°YÄ° LOOKBACK PERIOD")
    print("=" * 80)
    
    for pivot_type in ["Dip", "Peak"]:
        type_results = results_df[results_df["pivot_type"] == pivot_type]
        if len(type_results) == 0:
            continue
        
        best_lookback = None
        best_rate = 0
        
        for lookback in lookback_periods:
            lookback_results = type_results[type_results["lookback_days"] == lookback]
            if len(lookback_results) == 0:
                continue
            
            success_rate = (lookback_results["pure_signal"].sum() / len(lookback_results) * 100)
            if success_rate > best_rate:
                best_rate = success_rate
                best_lookback = lookback
        
        if best_lookback is not None:
            print(f"{pivot_type}: En iyi lookback = {best_lookback}g (%{best_rate:.1f} baÅŸarÄ±)")
    
    # DetaylÄ± sonuÃ§larÄ± CSV'ye kaydet
    output_file = "forward_test_pure_signals_results.csv"
    results_df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ DetaylÄ± sonuÃ§lar kaydedildi: {output_file}")
    
    return results_df

if __name__ == "__main__":
    results = forward_test_pure_signals()

